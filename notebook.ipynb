{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KBE25/hotel_sentiment/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d3711a3-e242-44c2-aa6b-333e6abc2fd2",
      "metadata": {
        "id": "9d3711a3-e242-44c2-aa6b-333e6abc2fd2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2bEDtTnmoYhn"
      },
      "id": "2bEDtTnmoYhn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview"
      ],
      "metadata": {
        "id": "dlQWMMfrolxs"
      },
      "id": "dlQWMMfrolxs"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jQGdfTfpoYkM"
      },
      "id": "jQGdfTfpoYkM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JGx6zWh8oYmr"
      },
      "id": "JGx6zWh8oYmr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lbq9MrdJoYpS"
      },
      "id": "lbq9MrdJoYpS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Business Understanding"
      ],
      "metadata": {
        "id": "Q9pTrIy_osiI"
      },
      "id": "Q9pTrIy_osiI"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dCNX1WQ5oYrz"
      },
      "id": "dCNX1WQ5oYrz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cd5gJMW_oYuZ"
      },
      "id": "Cd5gJMW_oYuZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UpJ6o83IoYwv"
      },
      "id": "UpJ6o83IoYwv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Understanding"
      ],
      "metadata": {
        "id": "Hcthe6dAou9p"
      },
      "id": "Hcthe6dAou9p"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "GghVE8nPozSp"
      },
      "id": "GghVE8nPozSp"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "id": "_vYTRd3ioYze"
      },
      "id": "_vYTRd3ioYze",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install symspellpy"
      ],
      "metadata": {
        "id": "srnhTPVSoY2O"
      },
      "id": "srnhTPVSoY2O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing relevant libraries\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import string\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "import spacy\n",
        "import emoji\n",
        "\n",
        "from symspellpy import SymSpell, Verbosity\n",
        "import pkg_resources\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "import emoji\n",
        "from symspellpy import SymSpell, Verbosity\n",
        "import pkg_resources\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import multiprocessing as mp\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "\n"
      ],
      "metadata": {
        "id": "RNgLYXq2oY47"
      },
      "id": "RNgLYXq2oY47",
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Data Preparation will contain the following parts:"
      ],
      "metadata": {
        "id": "b-J2wYrkpFHJ"
      },
      "id": "b-J2wYrkpFHJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Acquisition"
      ],
      "metadata": {
        "id": "qJQN9JdspGMy"
      },
      "id": "qJQN9JdspGMy"
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest dataset version\n",
        "path = kagglehub.dataset_download(\"thedevastator/booking-com-hotel-reviews\")\n"
      ],
      "metadata": {
        "id": "8rSs-E7qoY7y"
      },
      "id": "8rSs-E7qoY7y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the path for the dataset\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "zUqLrEVDoY-Z"
      },
      "id": "zUqLrEVDoY-Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The path where the data is in the environment\n",
        "base_dataset_directory = \"/kaggle/input/booking-com-hotel-reviews\"\n",
        "csv_file_name = \"booking_reviews copy.csv\"\n",
        "full_csv_path = os.path.join(base_dataset_directory, csv_file_name)\n",
        "df = pd.read_csv(full_csv_path)"
      ],
      "metadata": {
        "id": "EH3nHpkjoZBA"
      },
      "id": "EH3nHpkjoZBA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "pXP80x5spTu_"
      },
      "id": "pXP80x5spTu_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the dataframe\n",
        "\n",
        "This part of the project will contain an evaluation of the dataframa and the columns available in order to decide which ones to drop based on their relevance for the analysis.\n"
      ],
      "metadata": {
        "id": "G48vAq-MpWXD"
      },
      "id": "G48vAq-MpWXD"
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "GtQVLxfAoZEB"
      },
      "id": "GtQVLxfAoZEB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "T-QYPX7xoZG3"
      },
      "id": "T-QYPX7xoZG3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "7JbnXr1BoZJw"
      },
      "id": "7JbnXr1BoZJw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(-5)"
      ],
      "metadata": {
        "id": "vPV8SGoSoZMV"
      },
      "id": "vPV8SGoSoZMV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle potential NaN values for comparison between raw_review_text and review_text\n",
        "# For this I fill NaN with a placeholder string to avoid issues, as NaN != NaN\n",
        "df_temp = df.fillna({'review_text': '', 'raw_review_text': ''}).copy()\n",
        "\n",
        "# Count how many rows have identical content\n",
        "identical_reviews = (df_temp['review_text'] == df_temp['raw_review_text']).sum()\n",
        "# Only count rows where both are non-null\n",
        "total_reviews_comparable = len(df_temp) - df_temp['review_text'].isnull().sum() - df_temp['raw_review_text'].isnull().sum()\n",
        "\n",
        "print(f\"Number of reviews where 'review_text' and 'raw_review_text' are identical (after filling NaN): {identical_reviews}\")\n",
        "print(f\"Total comparable reviews (where both are non-null): {total_reviews_comparable}\")\n",
        "print(f\"Percentage identical: {((identical_reviews / total_reviews_comparable) * 100):.2f}%\")"
      ],
      "metadata": {
        "id": "M4C-3JA2oZPS"
      },
      "id": "M4C-3JA2oZPS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given that only 1.08% of review_text and raw_review_text are identical,this indicates significant differences between the two. Because of this it's crucial to understand the nature of these disparities before deciding which column to retain for further analysis."
      ],
      "metadata": {
        "id": "4TkfCqWXpmUe"
      },
      "id": "4TkfCqWXpmUe"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the length of 'review_text' and 'raw_review_text'\n",
        "df_temp['review_text_len'] = df_temp['review_text'].apply(len)\n",
        "df_temp['raw_review_text_len'] = df_temp['raw_review_text'].apply(len)\n",
        "\n",
        "# Look at descriptive statistics of lengths\n",
        "print(\"\\nDescriptive statistics for 'review_text' length:\")\n",
        "print(df_temp['review_text_len'].describe())\n",
        "\n",
        "print(\"\\nDescriptive statistics for 'raw_review_text' length:\")\n",
        "print(df_temp['raw_review_text_len'].describe())\n",
        "\n",
        "# Check for rows where one is significantly longer than the other (e.g., >20 characters difference)\n",
        "print(\"\\n--- Examples where review_text is MUCH longer (diff > 20 chars) ---\")\n",
        "longer_review_text_diff = df_temp[df_temp['review_text_len'] - df_temp['raw_review_text_len'] > 20]\n",
        "print(f\"Number of such rows: {len(longer_review_text_diff)}\")\n",
        "if not longer_review_text_diff.empty:\n",
        "    print(longer_review_text_diff[['review_text', 'raw_review_text']].head(3).to_string())\n",
        "\n",
        "print(\"\\n--- Examples where raw_review_text is MUCH longer (diff > 20 chars) ---\")\n",
        "longer_raw_review_text_diff = df_temp[df_temp['raw_review_text_len'] - df_temp['review_text_len'] > 20]\n",
        "print(f\"Number of such rows: {len(longer_raw_review_text_diff)}\")\n",
        "if not longer_raw_review_text_diff.empty:\n",
        "    print(longer_raw_review_text_diff[['review_text', 'raw_review_text']].head(3).to_string())"
      ],
      "metadata": {
        "id": "UW7eyV6zoZR6"
      },
      "id": "UW7eyV6zoZR6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find a few rows where they are different (and both non-empty) for manual inspection\n",
        "diff_reviews_sample = df_temp[(df_temp['review_text'] != df_temp['raw_review_text']) &\n",
        "                              (df_temp['review_text'] != '') & (df_temp['raw_review_text'] != '')].sample(min(5, len(df_temp))).copy()\n",
        "\n",
        "print(\"\\n--- Detailed Examples of Differences (5 random samples) ---\")\n",
        "for index, row in diff_reviews_sample.iterrows():\n",
        "    print(f\"\\nRow Index: {index}\")\n",
        "    print(f\"review_text:     '{row['review_text']}'\")\n",
        "    print(f\"raw_review_text: '{row['raw_review_text']}'\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "dLroB-bBoZUp"
      },
      "id": "dLroB-bBoZUp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the first few non-null entries\n",
        "print(\"First 10 non-null entries in 'meta' column:\")\n",
        "print(df['meta'].dropna().head(10).tolist())\n",
        "\n",
        "# Displaying a random sample\n",
        "print(\"\\n10 random non-null entries in 'meta' column:\")\n",
        "print(df['meta'].dropna().sample(10).tolist())"
      ],
      "metadata": {
        "id": "agY45fGboZXg"
      },
      "id": "agY45fGboZXg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the above checks, I will be dropping the following columns that are not relevant for this analysis:\n",
        "\n",
        "1. index: Redundant DataFrame index.\n",
        "\n",
        "2. images: Too sparse, and image analysis is out of scope for this analysis as we are using text for hotel rating prediction.\n",
        "\n",
        "3. crawled_at: Irrelevant timestamp for this analysis as this is when the review was crawled from the site.\n",
        "\n",
        "4. url: Unique identifier for the review page, no predictive power.\n",
        "\n",
        "5. hotel_url: Unique identifier for the hotel page, but this becomes redundant if hotel_name or hotel_id is used.\n",
        "\n",
        "6. meta: content is consistently redundant, specifying 'en-gb' language and 'booking.com' source, and therefore provides no unique or discriminative information for this analysis.\n",
        "\n",
        "7. review_text: as it seems to be a simplified version of raw_review_text and is better to keep the columns with full information to better extract richer features for the analysis."
      ],
      "metadata": {
        "id": "wnv7C5Fdp8aR"
      },
      "id": "wnv7C5Fdp8aR"
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping unnecesary columns\n",
        "# Create a list of columns to drop\n",
        "columns_to_drop = ['index', 'images', 'crawled_at', 'url', 'hotel_url', 'meta', 'review_text']\n",
        "\n",
        "# Perform the drop operation\n",
        "df_cleaned = df.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Inspecting new dataframe\n",
        "df_cleaned.info()"
      ],
      "metadata": {
        "id": "-9HCOMOdoZat"
      },
      "id": "-9HCOMOdoZat",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initial Missing Value Overview\n",
        "df_cleaned.isnull().sum()"
      ],
      "metadata": {
        "id": "w89emybNoZd2"
      },
      "id": "w89emybNoZd2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before analyzing the distribution of our target variable 'rating', it's crucial to address its missing values. As observed, the rating column contains 289 missing entries. For supervised learning, every data point used in the target distribution analysis and model training must have a defined target value.\n",
        "\n",
        "Therefore, I made the decision to drop all rows where the rating value was NaN. This ensures the integrity of our target variable. Given this drop accounts for only about 1.08% of our total dataset, the data loss is minimal and justified to maintain data quality for supervised learning."
      ],
      "metadata": {
        "id": "jx1ney9uqAp4"
      },
      "id": "jx1ney9uqAp4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping NAN from target variable 'rating'\n",
        "df_cleaned = df_cleaned.dropna(subset=['rating']).copy()"
      ],
      "metadata": {
        "id": "zw2jYlHaoZgj"
      },
      "id": "zw2jYlHaoZgj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional Missing Value Overview\n",
        "df_cleaned.isnull().sum()"
      ],
      "metadata": {
        "id": "DROpvEkhoZjb"
      },
      "id": "DROpvEkhoZjb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The additional missing values will be managed later in the Data processing part."
      ],
      "metadata": {
        "id": "J-EMsG5HqGSl"
      },
      "id": "J-EMsG5HqGSl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Target Variable Distribution Analysis\n",
        "\n",
        "For this project, the target variable is rating, which mean that I have two different ways to approach the solution:\n",
        "\n",
        "1.   A regression approach by predicting the exact rating\n",
        "2.   A classification approach by converting rating to sentiment categories\n",
        "\n",
        "So in this part, I will conduct a distribution analysis for both, since I have a numerical rating from the Booking.com data I will first approach a solution with a regression problem to predict a numerical rating and then explore the sentiment classification as an alternative."
      ],
      "metadata": {
        "id": "PmvJaencqbFh"
      },
      "id": "PmvJaencqbFh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rating Prediction (Regression Problem)"
      ],
      "metadata": {
        "id": "5ZYyqGOQqdvP"
      },
      "id": "5ZYyqGOQqdvP"
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating an histogram for the target variable 'rating'\n",
        "rating_column_name = 'rating'\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_cleaned[rating_column_name], bins=20, kde=True) # Adjust bins if rating scale is very small/large\n",
        "plt.title(f'Distribution of Hotel Ratings (Target Variable)')\n",
        "plt.xlabel('Rating Score')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()\n",
        "\n",
        "# Get descriptive statistics for the varible 'rating'\n",
        "print(f\"\\nDescriptive Statistics for '{rating_column_name}':\")\n",
        "print(df_cleaned[rating_column_name].describe())\n",
        "\n",
        "# Check for specific unique values (e.g., 1-10)\n",
        "if df_cleaned[rating_column_name].dtype in ['int64', 'float64']:\n",
        "    print(f\"\\nUnique values in '{rating_column_name}':\")\n",
        "    print(df_cleaned[rating_column_name].unique())\n",
        "    print(f\"\\nValue counts for '{rating_column_name}':\")\n",
        "    print(df_cleaned[rating_column_name].value_counts().sort_index())"
      ],
      "metadata": {
        "id": "vxUZnNZDptNH"
      },
      "id": "vxUZnNZDptNH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the histogram, the key findings are that the 'rating' column is a numerical target with ample data (26386 non-null entries). However, it exhibits a strong positive skew, with a mean of 8.56, and over 75% of ratings are 7.9 or higher, making lower ratings significantly sparse.\n",
        "\n",
        "This skew will cause regression models to be biased towards predicting higher ratings, potentially performing poorly on and underrepresenting the crucial, but rare, lower (negative) ratings.\n",
        "\n",
        "Moving forward with the regression to predict the rating will mean that:\n",
        "\n",
        "*   I will need to prioritize MAE/RMSE for evaluation and analyze errors across rating ranges.\n",
        "*  Employ robust regression models like Gradient Boosting Machines (XGBoost, LightGBM).\n",
        "*   Focus feature engineering on attributes indicative of negative sentiment to aid prediction of sparse low ratings.\n",
        "*   Consider converting to a classification problem by binning ratings if direct regression proves too challenging."
      ],
      "metadata": {
        "id": "VViH_j1Tqj48"
      },
      "id": "VViH_j1Tqj48"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sentiment Classification (Classification Problem derived from rating)"
      ],
      "metadata": {
        "id": "RM5D6a26qmva"
      },
      "id": "RM5D6a26qmva"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to categorize ratings into sentiments\n",
        "# The split for the binary classification was done to try to keep a 50/50 split\n",
        "def derive_binary_sentiment(rating):\n",
        "    if rating >= 9.0:\n",
        "        return 'Positive'\n",
        "    else:\n",
        "        return 'Negative'\n",
        "\n",
        "# Create the new binary sentiment column\n",
        "df_cleaned['sentiment_label'] = df_cleaned[rating_column_name].apply(derive_binary_sentiment)\n",
        "\n",
        "#df_classification['sentiment_label'] = df_classification['rating'].apply(derive_binary_sentiment)\n",
        "\n",
        "# Display the distribution of sentiment labels\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='sentiment_label', data=df_cleaned, order=['Negative', 'Positive'])\n",
        "plt.title('Distribution of Derived Binary Sentiment Labels (Threshold: 9.0)')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.show()\n",
        "\n",
        "# Print counts and percentages to quantify imbalance\n",
        "sentiment_counts = df_cleaned['sentiment_label'].value_counts()\n",
        "print(\"\\nDerived Binary Sentiment Label Counts:\")\n",
        "print(sentiment_counts)\n",
        "print(\"\\nDerived Binary Sentiment Label Proportions:\")\n",
        "print((df_cleaned['sentiment_label'].value_counts(normalize=True) * 100).round(2))\n"
      ],
      "metadata": {
        "id": "PTKWZeilptPu"
      },
      "id": "PTKWZeilptPu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your rating data was effectively transformed into a well-balanced binary classification target (Positive: 53.72%, Negative: 46.28%) using the rating 9.0 as a threshold. This near-even split mitigates class imbalance issues, aiding robust classifier training and evaluation.\n",
        "\n",
        "The limitations of this split is that, the 9.0 threshold is arbitrary, leading to a loss of original rating granularity where diverse dissatisfaction levels are grouped. Reviews just below 9.0 are categorized with truly negative ones, potentially misrepresenting nuanced sentiment. \"Neutral\" reviews might also fall into \"Negative\" based purely on score.\n",
        "\n",
        "To address the limitations, I will be performing a boundary analysis during model evaluation to understand misclassifications near the 9.0 mark as well a conducting detailed error analysis on miscategorized reviews."
      ],
      "metadata": {
        "id": "vpH_8wtpqq_Q"
      },
      "id": "vpH_8wtpqq_Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "qd4jEBhCqu2t"
      },
      "id": "qd4jEBhCqu2t"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling missing values"
      ],
      "metadata": {
        "id": "rVNJxDQwqvdE"
      },
      "id": "rVNJxDQwqvdE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Current missing values\n",
        "df_cleaned.isnull().sum()"
      ],
      "metadata": {
        "id": "Q9f_VShCqulT"
      },
      "id": "Q9f_VShCqulT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will manage the the missing values for 'review_title', 'nationality', 'raw_review_text' and 'tags' in the following way:\n",
        "\n",
        "1.  review_title: I will add a placeholder \"No Title\" to preserve data. This approach is ideal because only one value is missing, and mean/median/mode imputation isn't suitable for text.\n",
        "2.  nationality: I will fill in the NaNs with the mode so the most frequent nationality. Using the mode is a common and  reasonable approach for categorical features as it preserves the distribution of the existing data as much as possible by assuming the missing values are most likely to belong to the most common category. While it might introduce a slight bias towards the mode, for a small number of missing values (16 in this case), the impact will be minimal.\n",
        "\n",
        "3.  raw_review_text: I will add a placeholder in this case an empty string. In this case an empty String '' is the best option as in an NLP pipeline this will naturally result in no tokens or zero vectors, which is the correct representation for an absent review.\n",
        "\n",
        "4.  tags: I will add a placeholder in this case an empty string.\n"
      ],
      "metadata": {
        "id": "W6PFqeBrq3vJ"
      },
      "id": "W6PFqeBrq3vJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Review title\n",
        "df_cleaned['review_title'].fillna('No Title', inplace=True)\n",
        "\n",
        "# Nationality\n",
        "most_frequent_nationality = df_cleaned['nationality'].mode()[0]\n",
        "df_cleaned['nationality'].fillna(most_frequent_nationality, inplace=True)\n",
        "\n",
        "# Raw_review_text\n",
        "df_cleaned['raw_review_text'].fillna('', inplace=True)\n",
        "\n",
        "# Tags\n",
        "df_cleaned['tags'].fillna('', inplace=True)"
      ],
      "metadata": {
        "id": "R_ZhNIKCptR7"
      },
      "id": "R_ZhNIKCptR7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validating that the missing values were handled\n",
        "df_cleaned.isnull().sum()"
      ],
      "metadata": {
        "id": "DZ2ttvc9ptUV"
      },
      "id": "DZ2ttvc9ptUV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering from Structured Data\n",
        "\n",
        "The goal of this part is to extract more information from existing numerical and categorical features, especially time-related ones, to potentially improve model performance or provide deeper insights."
      ],
      "metadata": {
        "id": "6GEW30n4q-TP"
      },
      "id": "6GEW30n4q-TP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: Convert reviewed_at to Datetime object\n",
        "\n",
        "Convert reviewed_at in df_cleaned to a pandas datetime object as this allows easy extraction of year, month, day, day of week and facilitates date arithmetic."
      ],
      "metadata": {
        "id": "ahGs4w3wrDby"
      },
      "id": "ahGs4w3wrDby"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to datetime\n",
        "df_cleaned['reviewed_at'] = pd.to_datetime(df_cleaned['reviewed_at'])\n"
      ],
      "metadata": {
        "id": "pDi3LcbrptW1"
      },
      "id": "pDi3LcbrptW1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that reviewed_at is a datetime object, I can easily extract various time-based features.\n",
        "# Seasonality: Month, quarter, and day of week can capture seasonal trends in reviews.\n",
        "# Temporal Trends: Year can capture long-term trends or changes.\n",
        "# Recency: review_age_days\n",
        "\n",
        "# Basic features to create\n",
        "df_cleaned['review_year'] = df_cleaned['reviewed_at'].dt.year\n",
        "df_cleaned['review_month'] = df_cleaned['reviewed_at'].dt.month\n",
        "df_cleaned['review_day'] = df_cleaned['reviewed_at'].dt.day\n",
        "df_cleaned['review_day_of_week'] = df_cleaned['reviewed_at'].dt.dayofweek # Monday=0, Sunday=6\n",
        "df_cleaned['review_quarter'] = df_cleaned['reviewed_at'].dt.quarter\n",
        "\n",
        "# Age relative to the latest review date in the dataset\n",
        "latest_review_date = df_cleaned['reviewed_at'].max()\n",
        "df_cleaned['review_age_days'] = (latest_review_date - df_cleaned['reviewed_at']).dt.days\n",
        "\n",
        "print(\"\\nDataFrame after adding time-based features:\")\n",
        "print(df_cleaned[['reviewed_at', 'review_year', 'review_month', 'review_day', 'review_day_of_week', 'review_quarter', 'review_age_days']].head())"
      ],
      "metadata": {
        "id": "zdIGKhVZptZU"
      },
      "id": "zdIGKhVZptZU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Aggregation Features\n",
        "\n",
        "Reviewer centric metrics?"
      ],
      "metadata": {
        "id": "1WFybdwNrcgk"
      },
      "id": "1WFybdwNrcgk"
    },
    {
      "cell_type": "code",
      "source": [
        "#reviewer_stats = df_cleaned.groupby('reviewed_by').agg(reviewer_total_reviews=('reviewed_by', 'count'),reviewer_avg_rating=('rating', 'mean')).reset_index()\n",
        "#df_cleaned = pd.merge(df_cleaned, reviewer_stats, on='reviewed_by', how='left')\n",
        "\n",
        "#print(\"\\nDataFrame after adding aggregation features:\")\n",
        "#print(df_cleaned[['hotel_name', 'rating', 'hotel_avg_rating', 'hotel_total_reviews',\n",
        "#          'reviewed_by', 'reviewer_total_reviews', 'reviewer_avg_rating']].head())"
      ],
      "metadata": {
        "id": "hD8T-IMUptbv"
      },
      "id": "hD8T-IMUptbv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Selection"
      ],
      "metadata": {
        "id": "3-mElPOjrqp1"
      },
      "id": "3-mElPOjrqp1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target variable\n",
        "y = df_cleaned['rating']\n",
        "\n",
        "X = df_cleaned.drop(columns=[\n",
        "    'rating', 'reviewed_at', 'review_title', 'raw_review_text', 'tags',\n",
        "    'nationality', 'reviewed_by', 'hotel_name', 'sentiment_label'\n",
        "\n",
        "])\n"
      ],
      "metadata": {
        "id": "1hu0Bnw3pteH"
      },
      "id": "1hu0Bnw3pteH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only numerical columns for correlation calculation\n",
        "numerical_cols = X.select_dtypes(include=np.number).columns\n",
        "\n",
        "# Calculate correlation with the target variable\n",
        "correlations = X[numerical_cols].corrwith(y).sort_values(ascending=False)\n",
        "print(\"\\nCorrelation of numerical features with 'rating':\\n\", correlations)\n",
        "\n",
        "# Visualize correlation matrix among numerical features if you have many\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(X[numerical_cols].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Numerical Features')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Zl4Z3hA1ptgm"
      },
      "id": "Zl4Z3hA1ptgm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the correlation matrix, we will be dropping the following variables: review_quarter, review_day and review_year. These show extremely low correlation with rating and review_quarter is redundant with review_month. review_year is also redundant with review_age_days. Removing them reduces noise and multicollinearity.\n",
        "\n",
        "I'm keeping review_age_days because even if correlation is low, temporal features can have non-linear impacts or interactions not captured by simple correlation, warranting further evaluation by other methods."
      ],
      "metadata": {
        "id": "ObO1uoCzrwX-"
      },
      "id": "ObO1uoCzrwX-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns to drop based on low correlation and redundancy\n",
        "columns_to_drop_now = [\n",
        "    'review_quarter',\n",
        "    'review_day',\n",
        "    'review_year'\n",
        "]\n",
        "\n",
        "# Ensure these columns actually exist in X before dropping\n",
        "existing_columns_to_drop = [col for col in columns_to_drop_now if col in X.columns]\n",
        "\n",
        "if existing_columns_to_drop:\n",
        "    X_filtered = X.drop(columns=existing_columns_to_drop)\n",
        "    print(f\"\\nDropped columns: {existing_columns_to_drop}\")\n",
        "    print(\"\\nFeatures (X_filtered) columns after preliminary drops:\\n\", X_filtered.columns.tolist())\n",
        "    print(\"\\nShape of X_filtered:\", X_filtered.shape)\n",
        "else:\n",
        "    X_filtered = X.copy()\n",
        "    print(\"\\nNo additional columns to drop based on this correlation analysis.\")"
      ],
      "metadata": {
        "id": "qRtwB19Gpti_"
      },
      "id": "qRtwB19Gpti_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F-regression\n",
        "print(\"\\n--- Feature Selection using F-regression (SelectKBest) on X_filtered ---\")\n",
        "selector_f_reg_filtered = SelectKBest(score_func=f_regression, k='all')\n",
        "selector_f_reg_filtered.fit(X_filtered, y)\n",
        "f_scores_filtered = pd.DataFrame({'Feature': X_filtered.columns, 'F-Score': selector_f_reg_filtered.scores_, 'P-value': selector_f_reg_filtered.pvalues_})\n",
        "f_scores_filtered = f_scores_filtered.sort_values(by='F-Score', ascending=False)\n",
        "print(f_scores_filtered)\n",
        "\n",
        "# Mutual Information Regression\n",
        "print(\"\\n--- Feature Selection using Mutual Information Regression (SelectKBest) on X_filtered ---\")\n",
        "selector_mi_filtered = SelectKBest(score_func=mutual_info_regression, k='all')\n",
        "selector_mi_filtered.fit(X_filtered, y)\n",
        "mi_scores_filtered = pd.DataFrame({'Feature': X_filtered.columns, 'Mutual_Info_Score': selector_mi_filtered.scores_})\n",
        "mi_scores_filtered = mi_scores_filtered.sort_values(by='Mutual_Info_Score', ascending=False)\n",
        "print(mi_scores_filtered)"
      ],
      "metadata": {
        "id": "C9oRwmn8ptlU"
      },
      "id": "C9oRwmn8ptlU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the F-regression and Mutual Information scores we will drop and keep the following variables:\n",
        "\n",
        "Drop:\n",
        "\n",
        "1. review_day_of_week: Its F-score is low, and the P-value (0.109) is above the 0.05 significance threshold. The Mutual Information score is also extremely low (0.006). This indicates it has little to no linear or non-linear relationship with rating.\n",
        "\n",
        "Keep (for further evaluation by model-based methods):\n",
        "\n",
        "1. review_age_days: Exhibits high statistical significance (low P-value) and is the strongest feature by Mutual Information, suggesting a potentially strong non-linear relationship.\n",
        "\n",
        "2. review_month: While its Mutual Information score is low, its F-score's P-value (0.0348) is still below 0.05. It might have a subtle linear impact or interact with other features, so it's worth assessing with tree-based models next.\n",
        "\n",
        "As only 'review_month' and 'review_age_days' are left, I'm going to evaluate if it will be ok keeping both or not using a Variance Inflation Factor (VIF) calculation:"
      ],
      "metadata": {
        "id": "anWlPVo1r2rM"
      },
      "id": "anWlPVo1r2rM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a constant as this is a good practice for VIF calculation\n",
        "X_vif = X_filtered[['review_month', 'review_age_days']].copy() # Just these two for now\n",
        "X_vif['intercept'] = 1\n",
        "\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = X_vif.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
        "\n",
        "print(\"\\nVariance Inflation Factor (VIF) for review_month and review_age_days:\")\n",
        "print(vif_data)"
      ],
      "metadata": {
        "id": "afPNMykvptns"
      },
      "id": "afPNMykvptns",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Variance Inflation Factor (VIF) for both review_month and review_age_days is approximately 1.03. This score, being very close to 1, indicates extremely low multicollinearity between these two features.\n",
        "\n",
        "Crucially, these variables capture distinct temporal aspects. Review_month accounts for seasonality, reflecting potential cyclical patterns in hotel ratings throughout the year (e.g., holiday seasons, peak travel months). In contrast, review_age_days measures recency, indicating how old a review is, which can reflect current hotel conditions or reviewer sentiment trends over time.\n",
        "\n",
        "Since they provide independent information about different facets of time and do not exhibit problematic redundancy, retaining both enriches the model's understanding of review dynamics. This allows the model to leverage both seasonal influences and the impact of review recency, leading to a more comprehensive and potentially more accurate predictive capability without introducing noise or instability."
      ],
      "metadata": {
        "id": "YkX8oIBYr68C"
      },
      "id": "YkX8oIBYr68C"
    },
    {
      "cell_type": "code",
      "source": [
        "# Final cleaned df with feature engineering variables define through feature selection\n",
        "df_filtered = df_cleaned.drop(columns=[ 'review_quarter', 'review_day', 'review_year',  'review_day_of_week'])\n",
        "\n",
        "df_filtered.info()"
      ],
      "metadata": {
        "id": "-heFcJXYptqF"
      },
      "id": "-heFcJXYptqF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Preprocessing\n",
        "\n",
        "This text preprocessing methodology is meticulously designed to transform raw, unstructured review data into a clean, normalized, and semantically rich format suitable for advanced natural language processing tasks.\n",
        "\n",
        "This multi-stage process begins with fundamental cleanups, including lowercasing to standardize text representation and the removal of URLs and HTML tags to eliminate extraneous noise. Subsequently, emojis and emoticons are converted into descriptive text to capture their inherent sentiment, while the text is simultaneously tokenized into individual words. I then apply lemmatization to reduce words to their base forms, ensuring consistent representation across variations, and systematically remove punctuation and numbers to focus on meaningful lexical content. A crucial step involves comprehensive stop word removal, which not only leverages standard lists but also incorporates custom, domain-specific terms (e.g., \"hotel,\" \"room\") that lack discriminative power in review contexts.\n",
        "\n",
        "Furthermore, I implement sophisticated negation handling by tagging words that follow negations (e.g., \"good_NEG\" from \"not good\"), thus preserving accurate sentiment. Finally, optional spell correction is employed to address typographical errors, preventing data sparsity and ensuring that misspelled words contribute correctly to feature representation. This rigorous preprocessing pipeline is essential for generating high-quality features for subsequent TF-IDF modeling and enhancing the overall performance of our machine learning models.\n"
      ],
      "metadata": {
        "id": "yBP9ooqwsGGh"
      },
      "id": "yBP9ooqwsGGh"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize spaCy\n",
        "# Load a pre-trained English model. 'en_core_web_sm' is a good starting point.\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    print(\"spaCy 'en_core_web_sm' model loaded successfully.\")\n",
        "except OSError:\n",
        "    print(\"spaCy 'en_core_web_sm' model not found. Please run: !python -m spacy download en_core_web_sm\")\n",
        "    import sys\n",
        "    sys.exit(\"SpaCy model not found. Please download it first.\")"
      ],
      "metadata": {
        "id": "uxuzbFvdptsZ"
      },
      "id": "uxuzbFvdptsZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Clone my github to bring my helper function: processing_text.py file into my Colab environment.\n",
        "repo_url = \"https://github.com/KBE25/hotel_sentiment.git\"\n",
        "repo_name = \"hotel_sentiment\"\n",
        "\n",
        "# Check if the repo is already cloned to avoid re-cloning on successive runs\n",
        "if not os.path.exists(repo_name):\n",
        "    print(f\"Cloning {repo_name} from GitHub...\")\n",
        "    !git clone {repo_url}\n",
        "    print(f\"Repository '{repo_name}' cloned successfully.\")\n",
        "else:\n",
        "    print(f\"Repository '{repo_name}' already exists. Skipping clone.\")\n",
        "\n",
        "# Navigate into the cloned repository's directory\n",
        "# This is important so Python can find the helper file directly\n",
        "%cd {repo_name}/\n",
        "print(f\"Current working directory changed to: {os.getcwd()}\")"
      ],
      "metadata": {
        "id": "VydnFmjeptu4"
      },
      "id": "VydnFmjeptu4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The current working directory should now be the root of your cloned repo\n",
        "# 'processing_text.py' is directly in the root of my repository.\n",
        "path_to_add = os.getcwd()\n",
        "\n",
        "if path_to_add not in sys.path:\n",
        "    sys.path.append(path_to_add)\n",
        "    print(f\"Added '{path_to_add}' to sys.path for module import.\")"
      ],
      "metadata": {
        "id": "IjehQeXDptxR"
      },
      "id": "IjehQeXDptxR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Import the functions from my processing_text.py helper file\n",
        "try:\n",
        "    from processing_text import (preprocess_text_enhanced_spacy, parallelize_series_with_tqdm, worker_initializer)\n",
        "    print(\"Successfully imported preprocessing functions from 'processing_text.py'.\")\n",
        "except ImportError as e:\n",
        "    print(f\"Error importing functions from processing_text.py: {e}\")\n",
        "    print(\"Please check: 1. File name 'processing_text.py'. 2. Its location in your repo. 3. Python path.\")\n",
        "    # Exit the script if the helper cannot be loaded\n",
        "    sys.exit(\"Failed to import preprocessing helper. Exiting.\")"
      ],
      "metadata": {
        "id": "aw8tS3gWptzu"
      },
      "id": "aw8tS3gWptzu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Run the core text preprocessing\n",
        "# This step takes a really long time so after running it the next step will be to save it so is easier just to load the data and run the rest of the analysis\n",
        "if __name__ == '__main__':\n",
        "    text_cols_to_process = ['raw_review_text', 'review_title', 'tags']\n",
        "    processed_output_cols = [f'{col}_processed' for col in text_cols_to_process]\n",
        "\n",
        "    for col in text_cols_to_process:\n",
        "        print(f\"Starting parallel processing for column: '{col}' (with full spaCy pipeline)...\")\n",
        "        df_filtered[f'{col}_processed'] = parallelize_series_with_tqdm(\n",
        "            df_filtered[col],\n",
        "            preprocess_text_enhanced_spacy,\n",
        "            n_cores=None, # Use all available CPU cores\n",
        "            apply_spell_correction=True # Pass keyword arguments\n",
        "        )\n",
        "        print(f\"Finished processing column: '{col}'\")\n",
        "\n",
        "    print(\"\\n--- Processed Text Columns Sample (after all preprocessing) ---\")\n",
        "    print(df_filtered[processed_output_cols].head(2).to_string())\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "DCYawVYppt2R"
      },
      "id": "DCYawVYppt2R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 4. Saving the processed dataframe\n",
        "# This step saves the df_filtered (including original and new processed columns) to a file for later use, avoiding reprocessing.\n",
        "output_filepath_parquet = 'processed_reviews.parquet'"
      ],
      "metadata": {
        "id": "ySwCqEuOpt4k"
      },
      "id": "ySwCqEuOpt4k",
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be able to load the data saved in step (4) we are going to have to complete a couple of additional steps using Kaggle. After I completed step (4) and saved the df_filtered data I went ahead and downloaded the data and uploaded into Kaggle for easier management. To be able to recover this information the next steps are needed:\n",
        "\n",
        "1. Create an API connection with Kaggle\n",
        "2. Download the processed data from Kaggle\n",
        "3. Load the data\n"
      ],
      "metadata": {
        "id": "XcMLxaI02BvA"
      },
      "id": "XcMLxaI02BvA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Creating a connection with Kaggle API\n",
        "\n",
        "The code below is used to create a connection with Kaggle Public API. In this case this connection is done to be able to load the models that we saved in Kaggle.\n",
        "\n",
        "The only change that is needed below is to edit the following part by finding your API token information in your Kaggle account settings part:\n",
        "\n",
        "*   \"username\":\"ADD_KEY HERE\"\n",
        "*   \"key\":\"ADD_KEY HERE\"\n",
        "\n",
        "IMPORTANT - After you ran the below code, make sure to delete your 'username' and 'key' as that information is personal and should not be made available in any public site like Github. More information on Kaggle's API can be found here."
      ],
      "metadata": {
        "id": "A0MyowCm2-ke"
      },
      "id": "A0MyowCm2-ke"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Go to Kaggle and get your API public https://www.kaggle.com/docs/api\n",
        "api_key = {\n",
        "    \"username\":\"\", #add your Kaggle API username\n",
        "    \"key\":\"\"       #add your Kaggle API key\n",
        "    }\n",
        "\n",
        "# uses pathlib Path\n",
        "kaggle_path = Path('/root/.kaggle')\n",
        "os.makedirs(kaggle_path, exist_ok=True)\n",
        "\n",
        "# opens file and dumps python dict to json object\n",
        "with open (kaggle_path/'kaggle.json', 'w') as handl:\n",
        "    json.dump(api_key,handl)\n",
        "\n",
        "os.chmod(kaggle_path/'kaggle.json', 600)\n",
        "\n",
        "#IMPORTANT: after running this code, delete your username and key"
      ],
      "metadata": {
        "id": "4Qk7SNWBpt7j"
      },
      "id": "4Qk7SNWBpt7j",
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " #### 2. Downloading the dataset from Kaggle to Colab"
      ],
      "metadata": {
        "id": "epR5MqvV3zKB"
      },
      "id": "epR5MqvV3zKB"
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d karinabe25us/df-filtered\n",
        "! unzip df-filtered.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UchRXh8xMFV",
        "outputId": "1767a1e9-5da6-4156-bc59-da68f73c9bec"
      },
      "id": "5UchRXh8xMFV",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/karinabe25us/df-filtered\n",
            "License(s): apache-2.0\n",
            "df-filtered.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  df-filtered.zip\n",
            "replace processed_reviews.parquet? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: processed_reviews.parquet  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " #### 3. Loading the dataset using pandas"
      ],
      "metadata": {
        "id": "GIu2enM64Nni"
      },
      "id": "GIu2enM64Nni"
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the model\n",
        "\n",
        "# Define the full path to the processed Parquet file\n",
        "file_path = '/content/hotel_sentiment/processed_reviews.parquet'\n",
        "\n",
        "# Load the DataFrame directly from the Parquet file\n",
        "df_filtered = pd.read_parquet(file_path)\n",
        "\n",
        "#Confirming the dataset has the correct information\n",
        "print(df_filtered.info())\n",
        "print(df_filtered.head().to_string())\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xomcg9-RxMID",
        "outputId": "4037bb83-f9ed-4538-d96a-7f3215c079eb"
      },
      "id": "xomcg9-RxMID",
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26386 entries, 0 to 26385\n",
            "Data columns (total 15 columns):\n",
            " #   Column                     Non-Null Count  Dtype         \n",
            "---  ------                     --------------  -----         \n",
            " 0   review_title               26386 non-null  object        \n",
            " 1   reviewed_at                26386 non-null  datetime64[ns]\n",
            " 2   reviewed_by                26386 non-null  object        \n",
            " 3   hotel_name                 26386 non-null  object        \n",
            " 4   avg_rating                 26386 non-null  float64       \n",
            " 5   nationality                26386 non-null  object        \n",
            " 6   rating                     26386 non-null  float64       \n",
            " 7   raw_review_text            26386 non-null  object        \n",
            " 8   tags                       26386 non-null  object        \n",
            " 9   sentiment_label            26386 non-null  object        \n",
            " 10  review_month               26386 non-null  int32         \n",
            " 11  review_age_days            26386 non-null  int64         \n",
            " 12  raw_review_text_processed  26386 non-null  object        \n",
            " 13  review_title_processed     26386 non-null  object        \n",
            " 14  tags_processed             26386 non-null  object        \n",
            "dtypes: datetime64[ns](1), float64(2), int32(1), int64(1), object(10)\n",
            "memory usage: 2.9+ MB\n",
            "None\n",
            "                                                                                                        review_title reviewed_at reviewed_by              hotel_name  avg_rating     nationality  rating                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         raw_review_text                                                                                           tags sentiment_label  review_month  review_age_days                                                                                                                                                                                                                                                                                                                                                      raw_review_text_processed                                                          review_title_processed                                                          tags_processed\n",
            "0                                                                                                        Exceptional  2021-07-11      Kyrylo         Villa Pura Vida         9.7          Poland    10.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <p class=\"review_pos \"><svg aria-label=\"Positive point\" class=\"bk-icon -fonticon-plus review_item_icon\" fill=\"#008009\" height=\"14\" role=\"img\" width=\"14\" viewbox=\"0 0 32 32\" aria-hidden=\"true\" focusable=\"false\">\\n  <path d=\"M32 16c0 8.836-7.162 16-16 16-8.834 0-16-5.74-16-16C0 6.451 7.166 0 16 0c8.838 0 16 7.162 16 16zm-6.4-2.585c0-.369-.031-.616-.4-.616h-5.998V7.018c0-.369-.297-.62-.666-.62h-5.068c-.369 0-.666.251-.666.62v5.781H6.901c-.369 0-.499.247-.499.616v5.118c0 .369.132.666.499.666H12.8v5.833c0 .369.297.565.666.565h5.068c.369 0 .666-.196.666-.565v-5.833h5.998c.369 0 .4-.297.4-.666v-5.118z\"></path>\\n</svg><span itemprop=\"reviewBody\">Everything was perfect! Quite, cozy place to relax.</span></p>                  Business trip~Solo traveller~Junior Suite~Stayed 1 night~Submitted via mobile        Positive             7                8                                                                                                                                                                                                                                                                                                                                                             perfect copy relax                                                                     exceptional      business trip solo traveller junior suite stay night submit mobile\n",
            "1                                                                  I highly recommend this b&b! We enjoyed it a lot!  2019-11-24     Dimitri         Villa Pura Vida         9.7         Belgium     9.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              <p class=\"review_pos \"><svg aria-label=\"Positive point\" class=\"bk-icon -fonticon-plus review_item_icon\" fill=\"#008009\" height=\"14\" role=\"img\" width=\"14\" viewbox=\"0 0 32 32\" aria-hidden=\"true\" focusable=\"false\">\\n  <path d=\"M32 16c0 8.836-7.162 16-16 16-8.834 0-16-5.74-16-16C0 6.451 7.166 0 16 0c8.838 0 16 7.162 16 16zm-6.4-2.585c0-.369-.031-.616-.4-.616h-5.998V7.018c0-.369-.297-.62-.666-.62h-5.068c-.369 0-.666.251-.666.62v5.781H6.901c-.369 0-.499.247-.499.616v5.118c0 .369.132.666.499.666H12.8v5.833c0 .369.297.565.666.565h5.068c.369 0 .666-.196.666-.565v-5.833h5.998c.369 0 .4-.297.4-.666v-5.118z\"></path>\\n</svg><span itemprop=\"reviewBody\">Very friendly host and perfect breakfast!</span></p>                           Leisure trip~Couple~Deluxe Suite~Stayed 1 night~Submitted via mobile        Positive            11              603                                                                                                                                                                                                                                                                                                                                                friendly host perfect breakfast                                                  highly recommend b&b enjoy lot               leisure trip couple deluxe suite stay night submit mobile\n",
            "2                                                                                                        Exceptional  2020-01-03    Virginia  Hydro Palace Apartment         9.2  United Kingdom    10.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              <p class=\"review_neg \"><svg aria-label=\"Negative point\" class=\"bk-icon -fonticon-removecircle review_item_icon\" fill=\"#BDBDBD\" height=\"14\" role=\"img\" width=\"14\" viewbox=\"0 0 32 32\" aria-hidden=\"true\" focusable=\"false\"><path d=\"m16 0c-8.84 0-16 7.16-16 16s7.16 16 16 16 16-7.16 16-16-7.16-16-16-16zm8 17.6h-16v-3.2h16z\"></path></svg><span itemprop=\"reviewBody\">It was just what we wanted for a week by the beach in winter</span></p>,<p class=\"review_pos \"><svg aria-label=\"Positive point\" class=\"bk-icon -fonticon-plus review_item_icon\" fill=\"#008009\" height=\"14\" role=\"img\" width=\"14\" viewbox=\"0 0 32 32\" aria-hidden=\"true\" focusable=\"false\">\\n  <path d=\"M32 16c0 8.836-7.162 16-16 16-8.834 0-16-5.74-16-16C0 6.451 7.166 0 16 0c8.838 0 16 7.162 16 16zm-6.4-2.585c0-.369-.031-.616-.4-.616h-5.998V7.018c0-.369-.297-.62-.666-.62h-5.068c-.369 0-.666.251-.666.62v5.781H6.901c-.369 0-.499.247-.499.616v5.118c0 .369.132.666.499.666H12.8v5.833c0 .369.297.565.666.565h5.068c.369 0 .666-.196.666-.565v-5.833h5.998c.369 0 .4-.297.4-.666v-5.118z\"></path>\\n</svg><span itemprop=\"reviewBody\">Location was fab, apartment quiet and very well-equipped. Spotless clean.</span></p>               Leisure trip~Couple~Apartment with Sea View~Stayed 6 nights~Submitted via mobile        Positive             1              563                                                                                                                                                                                                                                                                                                       want week beach winter location fab apartment quiet equip spotless clean                                                                     exceptional         leisure trip couple apartment sea view stay night submit mobile\n",
            "3                My stay in the house was a experiencing bliss in luxury. The house is sheer touch of beauty wrapped  2019-09-08      Kannan         Villa Pura Vida         9.7     Netherlands    10.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               <p class=\"review_pos \"><svg aria-label=\"Positive point\" class=\"bk-icon -fonticon-plus review_item_icon\" fill=\"#008009\" height=\"14\" role=\"img\" width=\"14\" viewbox=\"0 0 32 32\" aria-hidden=\"true\" focusable=\"false\">\\n  <path d=\"M32 16c0 8.836-7.162 16-16 16-8.834 0-16-5.74-16-16C0 6.451 7.166 0 16 0c8.838 0 16 7.162 16 16zm-6.4-2.585c0-.369-.031-.616-.4-.616h-5.998V7.018c0-.369-.297-.62-.666-.62h-5.068c-.369 0-.666.251-.666.62v5.781H6.901c-.369 0-.499.247-.499.616v5.118c0 .369.132.666.499.666H12.8v5.833c0 .369.297.565.666.565h5.068c.369 0 .666-.196.666-.565v-5.833h5.998c.369 0 .4-.297.4-.666v-5.118z\"></path>\\n</svg><span itemprop=\"reviewBody\">My stay in the house was a experiencing bliss in luxury. The house is sheer touch of beauty wrapped by luxury and complimented with kindness and care  from Lisbette &amp; her parents making it a most remarkable stay.</span></p>                 Business trip~Solo traveller~Junior Suite~Stayed 4 nights~Submitted via mobile        Positive             9              680                                                                                                                                                                                                                                                house experience bliss luxury house sheer touch beauty wrap luxury compliment kindness care diskette amp parent make remarkable                     house experience bliss luxury house sheer touch beauty wrap      business trip solo traveller junior suite stay night submit mobile\n",
            "4  One bedroom apartment with wonderful view and free, secure parking, but not close enough  to the main beach area.  2019-06-23         Sue  Hydro Palace Apartment         9.2    South Africa     9.2  <p class=\"review_neg \"><svg aria-label=\"Negative point\" class=\"bk-icon -fonticon-removecircle review_item_icon\" fill=\"#BDBDBD\" height=\"14\" role=\"img\" width=\"14\" viewbox=\"0 0 32 32\" aria-hidden=\"true\" focusable=\"false\"><path d=\"m16 0c-8.84 0-16 7.16-16 16s7.16 16 16 16 16-7.16 16-16-7.16-16-16-16zm8 17.6h-16v-3.2h16z\"></path></svg><span itemprop=\"reviewBody\">The building itself has a very musty smell in the hallway (despite being built in 1988), but the apartment itself smells good, which makes it bearable. \\nWhen showering, the hot water goes off every 2-3 minutes for about 20-30 seconds and then only cold water comes out. The hot water then comes back again. This should be checked out. That is the only thing we didnt like about the apartment. </span></p>,<p class=\"review_pos \"><svg aria-label=\"Positive point\" class=\"bk-icon -fonticon-plus review_item_icon\" fill=\"#008009\" height=\"14\" role=\"img\" width=\"14\" viewbox=\"0 0 32 32\" aria-hidden=\"true\" focusable=\"false\">\\n  <path d=\"M32 16c0 8.836-7.162 16-16 16-8.834 0-16-5.74-16-16C0 6.451 7.166 0 16 0c8.838 0 16 7.162 16 16zm-6.4-2.585c0-.369-.031-.616-.4-.616h-5.998V7.018c0-.369-.297-.62-.666-.62h-5.068c-.369 0-.666.251-.666.62v5.781H6.901c-.369 0-.499.247-.499.616v5.118c0 .369.132.666.499.666H12.8v5.833c0 .369.297.565.666.565h5.068c.369 0 .666-.196.666-.565v-5.833h5.998c.369 0 .4-.297.4-.666v-5.118z\"></path>\\n</svg><span itemprop=\"reviewBody\">The view was great, the apartment furnished in a modern style and equipped with everything you may need. The apartment was clean. \\nThere is free, secure parking outside in the buildings parking lot or downstairs in the garage. \\nJan always responded promptly to all messages sent via Booking.com messenger.  </span></p>  Leisure trip~People with friends~Apartment with Sea View~Stayed 4 nights~Submitted via mobile        Positive             6              757  building musty smell hallway despite build apartment smell good make bearable shower hot water go minute second cold water come hot water come check thing like_NEG apartment view great apartment furnish modern style equip need apartment clean free secure parking outside building parking lot downstairs garage jan respond promptly message send booking.com messenger  bedroom apartment wonderful view free secure parking close_NEG main beach area  leisure trip people friend apartment sea view stay night submit mobile\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bDmQ-KXXxMKi"
      },
      "id": "bDmQ-KXXxMKi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cNdGXFGHxMM6"
      },
      "id": "cNdGXFGHxMM6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JigTDliDxMPh"
      },
      "id": "JigTDliDxMPh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PLrFSWScxMSC"
      },
      "id": "PLrFSWScxMSC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TWN3LMn-xMUT"
      },
      "id": "TWN3LMn-xMUT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LTASlLMJxMWu"
      },
      "id": "LTASlLMJxMWu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tw67_URixMZF"
      },
      "id": "Tw67_URixMZF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "So9yiRnMxMbl"
      },
      "id": "So9yiRnMxMbl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBCj71CGxMeF"
      },
      "id": "dBCj71CGxMeF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c1LHeFVpxMgn"
      },
      "id": "c1LHeFVpxMgn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xro92etwxMjB"
      },
      "id": "Xro92etwxMjB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M22NA2_RxMlo"
      },
      "id": "M22NA2_RxMlo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iWcEcSVWxMoO"
      },
      "id": "iWcEcSVWxMoO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_dYEAvxtxMqt"
      },
      "id": "_dYEAvxtxMqt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PtF9tXqUxMtM"
      },
      "id": "PtF9tXqUxMtM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lFT6CBFexMv7"
      },
      "id": "lFT6CBFexMv7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5PtP8ufExMyZ"
      },
      "id": "5PtP8ufExMyZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kGJdZuInxM04"
      },
      "id": "kGJdZuInxM04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s0hKA1XAxM3Z"
      },
      "id": "s0hKA1XAxM3Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lzLaAUGIxM6O"
      },
      "id": "lzLaAUGIxM6O",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (learn-env)",
      "language": "python",
      "name": "learn-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}